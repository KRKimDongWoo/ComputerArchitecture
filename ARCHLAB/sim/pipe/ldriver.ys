#######################################################################
# Test for copying block of size 63;
#######################################################################
	.pos 0
main:	irmovq Stack, %rsp  	# Set up stack pointer

	# Set up arguments for copy function and then invoke it
	irmovq $63, %rdx		# src and dst have 63 elements
	irmovq dest, %rsi	# dst array
	irmovq src, %rdi	# src array
	call ncopy		 
	halt			# should halt with num nonzeros in %rax
StartFun:
#/* $begin ncopy-ys */
##################################################################
# ncopy.ys - Copy a src block of len words to dst.
# Return the number of positive words (>0) contained in src.
#
# Include your name and ID here.
#
# Describe how and why you modified the baseline code.
#
##################################################################
# Do not modify this portion
# Function prologue.
# %rdi = src, %rsi = dst, %rdx = len
ncopy:

##################################################################
# You can modify this portion

	xorq %rax, %rax			#count = 0;

Lstart:
	iaddq $-10, %rdx
	jg L0a
	jmp PreAdjust

L0a:	
	mrmovq (%rdi), %r10
	mrmovq $8(%rdi), %r11
	rmmovq %r10, (%rsi)
	rmmovq %r11, $8(%rsi)
	andq %r10, %r10
	jle L0b
	iaddq $1, %rax
L0b:
	andq %r11, %r11
	jle L1a
	iaddq $1, %rax

L1a:	
	mrmovq $16(%rdi), %r10
	mrmovq $24(%rdi), %r11
	rmmovq %r10, $16(%rsi)
	rmmovq %r11, $24(%rsi)
	andq %r10, %r10
	jle L1b
	iaddq $1, %rax
L1b:
	andq %r11, %r11
	jle L2a
	iaddq $1, %rax

L2a:	
	mrmovq $32(%rdi), %r10
	mrmovq $40(%rdi), %r11
	rmmovq %r10, $32(%rsi)
	rmmovq %r11, $40(%rsi)
	andq %r10, %r10
	jle L2b
	iaddq $1, %rax
L2b:
	andq %r11, %r11
	jle L3a
	iaddq $1, %rax

L3a:	
	mrmovq $48(%rdi), %r10
	mrmovq $56(%rdi), %r11
	rmmovq %r10, $48(%rsi)
	rmmovq %r11, $56(%rsi)
	andq %r10, %r10
	jle L3b
	iaddq $1, %rax
L3b:
	andq %r11, %r11
	jle L4a
	iaddq $1, %rax

L4a:	
	mrmovq $64(%rdi), %r10
	mrmovq $72(%rdi), %r11
	rmmovq %r10, $64(%rsi)
	rmmovq %r11, $72(%rsi)
	andq %r10, %r10
	jle L4b
	iaddq $1, %rax
L4b:
	andq %r11, %r11
	jle Lend
	iaddq $1, %rax

Lend:
	iaddq $80, %rsi
	iaddq $80, %rdi
	jmp Lstart

JumpTable:
.quad Done
.quad Adjust10
.quad Adjust9
.quad Adjust8
.quad Adjust7
.quad Adjust6
.quad Adjust5
.quad Adjust4
.quad Adjust3
.quad Adjust2
.quad Adjust1

PreAdjust:
	iaddq $10, %rdx
	addq %rdx, %rdx
	addq %rdx, %rdx
	addq %rdx, %rdx
	mrmovq JumpTable(%rdx), %rdx
	mrmovq (%rdi), %r12
	mrmovq $8(%rdi), %r11
	pushq %rdx
	mrmovq $16(%rdi), %r9
	mrmovq $24(%rdi), %r8
	ret
	
Adjust1:
	mrmovq $72(%rdi), %r10
	rmmovq %r10, $72(%rsi)
	andq %r10, %r10
	jle Adjust2
	iaddq $1, %rax
Adjust2:
	mrmovq $64(%rdi), %r10
	rmmovq %r10, $64(%rsi)
	andq %r10, %r10
	jle Adjust3
	iaddq $1, %rax
Adjust3:
	mrmovq $56(%rdi), %r10
	rmmovq %r10, $56(%rsi)
	andq %r10, %r10
	jle Adjust4
	iaddq $1, %rax
Adjust4:
	mrmovq $48(%rdi), %r10
	rmmovq %r10, $48(%rsi)
	andq %r10, %r10
	jle Adjust5
	iaddq $1, %rax
Adjust5:
	mrmovq $40(%rdi), %r10
	rmmovq %r10, $40(%rsi)
	andq %r10, %r10
	jle Adjust6
	iaddq $1, %rax
Adjust6:
	mrmovq $32(%rdi), %r10
	rmmovq %r10, $32(%rsi)
	andq %r10, %r10
	jle Adjust7
	iaddq $1, %rax
Adjust7:
	rmmovq %r8, $24(%rsi)
	andq %r8, %r8
	jle Adjust8
	iaddq $1, %rax
Adjust8:
	rmmovq %r9, $16(%rsi)
	andq %r9, %r9
	jle Adjust9
	iaddq $1, %rax
Adjust9:
	rmmovq %r11, $8(%rsi)
	andq %r11, %r11
	jle Adjust10
	iaddq $1, %rax
Adjust10:
	rmmovq %r12, (%rsi)
	andq %r12, %r12
	jle Done
	iaddq $1, %rax

##################################################################
# Do not modify the following section of code
# Function epilogue.
Done:
	ret
################################################################## 
# Keep the following label at the end of your function
End:
#/* $end ncopy-ys */
EndFun:

###############################
# Source and destination blocks 
###############################
	.align 8
src:
	.quad 1
	.quad -2
	.quad 3
	.quad 4
	.quad -5
	.quad 6
	.quad 7
	.quad 8
	.quad -9
	.quad 10
	.quad -11
	.quad -12
	.quad 13
	.quad 14
	.quad -15
	.quad -16
	.quad -17
	.quad 18
	.quad 19
	.quad 20
	.quad -21
	.quad -22
	.quad 23
	.quad 24
	.quad -25
	.quad 26
	.quad 27
	.quad 28
	.quad -29
	.quad -30
	.quad -31
	.quad -32
	.quad -33
	.quad 34
	.quad 35
	.quad -36
	.quad 37
	.quad 38
	.quad -39
	.quad 40
	.quad -41
	.quad 42
	.quad 43
	.quad -44
	.quad 45
	.quad -46
	.quad -47
	.quad -48
	.quad -49
	.quad 50
	.quad 51
	.quad 52
	.quad 53
	.quad -54
	.quad 55
	.quad -56
	.quad 57
	.quad -58
	.quad -59
	.quad -60
	.quad -61
	.quad -62
	.quad -63
	.quad 0xbcdefa # This shouldn't get moved

	.align 16
Predest:
	.quad 0xbcdefa
dest:
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
Postdest:
	.quad 0xdefabc

.align 8
# Run time stack
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0

Stack:
